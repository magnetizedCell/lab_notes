### Install gpu card on each node.
### login to a node.
### ```ubuntu-drivers devices``` to check the gpu is correctly installed.
![Screenshot from 2022-10-19 21-51-34](https://user-images.githubusercontent.com/80142550/196695966-486d76bc-b174-40a0-a24a-a5f61fd6b61f.png)
Here, driver "nvidia-driver-515-open" is recommended. But we use the gpu for server usecase only, install "nvidia-driver-515-server" by ```sudo apt install nvidia-driver-515-server```

### Install cuda toolkit
Visit https://developer.nvidia.com/cuda-downloads and follow the instruction.
Here we install current latest version 11.8

![Screenshot from 2022-10-19 22-28-50](https://user-images.githubusercontent.com/80142550/196704995-9a4a882b-d76b-435f-8fea-605d1d66cbe0.png)

### Validate installation
1. version check  
Many sites shows ```nvcc -V``` to check cuda version, but in our case it did not exist.
In our case, ```/usr/local/cuda-11.8/bin/nvcc -V```   worked.
![Screenshot from 2022-10-19 22-32-36](https://user-images.githubusercontent.com/80142550/196705896-2972ebe7-a9ad-44c8-b476-91fb7ef2ee04.png)

2. operation check  
Now, we install ```pytorch``` and ```cupy```, those let gpu compute.
```sudo apt install python3-pip``` to install ```pip```, a python package manager.
Follow official instructions ([pytorch](https://pytorch.org/get-started/locally/), [cupy](https://docs.cupy.dev/en/stable/install.html)) to install pytorch with nearest-version cuda support.
As pytorch now has cuda 11.6 as latest support, we use it.
```pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116``` to install pytorch.
```pip3 install cupy-cuda11x``` to install cupy.
Additionally, ```pip3 install matplotlib```.

```python3``` to open python3 command line. Execute the lines below.

```
import torch
print(torch.cuda.is_available()) # Should print True
import numpy as np
arr = np.random.uniform(0, 1, (1024, 1024, 1024))
arr = torch.Tensor(arr).to(0)
```

The code above creates a large array and copy it to gpu memory.
```nvidia-smi``` will show that gpu memory is occupied by the array.

![Screenshot from 2022-10-19 22-49-44](https://user-images.githubusercontent.com/80142550/196710495-ac43df6c-6a70-41c1-b674-ad3da0e86722.png)

Next, we use cupy to check operation.
```wget https://raw.githubusercontent.com/cupy/cupy/master/examples/kmeans/kmeans.py``` to download sample code.
Changing num, ```python3 kmeans.py --num {num}``` to see the difference!


![Screenshot from 2022-10-19 23-15-46](https://user-images.githubusercontent.com/80142550/196716731-07bdf1c0-4bbe-4c96-b792-167d149b1038.png)

I have no idea why but first run on gpu takes longer time than later run.

![Screenshot from 2022-10-20 11-19-01](https://user-images.githubusercontent.com/80142550/196840882-ae515db5-073e-4add-805a-a65c439163f1.png)

